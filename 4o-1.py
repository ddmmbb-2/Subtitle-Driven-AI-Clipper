import os
import subprocess
import srt
import tkinter as tk
from tkinter import filedialog, simpledialog, messagebox, scrolledtext
from datetime import timedelta
import requests
import re
import whisper
from openai import OpenAI
import json
import sys # Import sys to check platform for ffmpeg path
import threading # Import threading for background tasks (optional but good for GUI)
import traceback # Import traceback for detailed error info

# --- Configuration Handling ---
CONFIG_FILE = "config.json"

# é è¨­çš„ AI æç¤ºè©æ¨¡æ¿ï¼ŒåŒ…å«ä¸€å€‹ä½”ä½ç¬¦ {subtitle_content} ç”¨æ–¼æ’å…¥å­—å¹•å…§å®¹
DEFAULT_AI_PROMPT_TEMPLATE = """ä½ æ˜¯ä¸€ä½å°ˆæ¥­å½±ç‰‡å‰ªè¼¯åŠ©ç†ã€‚
ä»¥ä¸‹æ˜¯å­—å¹•æ®µè½ï¼š
{subtitle_content}
è«‹æ ¹æ“šé€™äº›å­—å¹•å…§å®¹ï¼Œæ€è€ƒå¦‚ä½•ä¿®æ”¹éŒ¯è­¯çš„éƒ¨åˆ†ä¸¦è¦åŠƒä¸€å€‹æµæš¢çš„å‰ªè¼¯æ–¹æ¡ˆï¼Œä»¥æœ‰æ•ˆåœ°è¡¨é”å½±ç‰‡çš„ä¸»é¡Œã€‚
å‰ªè¼¯æ™‚è«‹å‹™å¿…ä¿ç•™å®Œæ•´çš„å¥å­æˆ–æ„ç¾©å–®å…ƒï¼Œä¸è¦æˆªæ–·å®Œæ•´çš„æ®µè½ åƒ…åšæ±ºå®šæ¯æ®µå­—å¹•çš„ç•™å­˜
è«‹**åªå›å‚³æ™‚é–“ç¯„åœæ¸…å–®**ï¼Œæ¯è¡Œä¸€æ®µæ™‚é–“ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
é©ç•¶çš„é ç•™èªéŸ³èˆ‡çµå°¾çš„ç·©è¡æ™‚é–“!
00:00:03.000 - 00:00:08.000
00:01:15.500 - 00:01:22.000

è«‹ä¸è¦æä¾›ä»»ä½•è§£é‡‹ã€æ‘˜è¦ã€è©•è«–æˆ–èªªæ˜ã€‚åªèƒ½å›å‚³æ™‚é–“æ®µã€‚"""


DEFAULT_CONFIG = {
    "llm_type": "gpt", # 'gpt' or 'ollama'
    "gpt_api_key": "",
    "gpt_model_name": "gpt-4o-mini",
    "ollama_api_base": "http://localhost:11434/v1", # Default Ollama API base URL (OpenAI compatible)
    "ollama_model_name": "llama3", # Default Ollama model
    "ffmpeg_path": "./ffmpeg/bin/ffmpeg.exe" if sys.platform == "win32" else "/usr/local/bin/ffmpeg", # Default path based on OS
    "output_dir": "out",
    "buffer_time": 0.5, # Seconds buffer before and after LLM suggested times
    "min_duration": 2.0, # Minimum duration for a clip in seconds
    "whisper_model": "small", # Whisper model size (tiny, base, small, medium, large)
    "ai_prompt_template": DEFAULT_AI_PROMPT_TEMPLATE # Add prompt template to config
}

app_config = DEFAULT_CONFIG.copy() # Global config dictionary

def load_config():
    """Loads configuration from config.json."""
    global app_config
    if os.path.exists(CONFIG_FILE):
        with open(CONFIG_FILE, "r", encoding="utf-8") as f:
            try:
                loaded_config = json.load(f)
                # Update default config with loaded values, keeping new default keys if they exist
                # Special handling for prompt template to ensure newline characters are loaded correctly
                if "ai_prompt_template" in loaded_config and isinstance(loaded_config["ai_prompt_template"], str):
                     # Replace escaped newlines if necessary (json might escape them)
                     loaded_config["ai_prompt_template"] = loaded_config["ai_prompt_template"].replace('\\n', '\n')

                for key, value in DEFAULT_CONFIG.items():
                     if key not in loaded_config or loaded_config[key] is None: # Also handle None values
                         loaded_config[key] = value
                app_config.update(loaded_config)
                print("âœ… é…ç½®è¼‰å…¥æˆåŠŸ")
            except json.JSONDecodeError:
                print("âš ï¸ ç„¡æ•ˆçš„é…ç½®æª”æ¡ˆï¼Œè¼‰å…¥é è¨­é…ç½®")
                app_config = DEFAULT_CONFIG.copy()
            except Exception as e:
                 print(f"âš ï¸ è¼‰å…¥é…ç½®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}ï¼Œè¼‰å…¥é è¨­é…ç½®")
                 traceback.print_exc()
                 app_config = DEFAULT_CONFIG.copy()
    else:
        print("â„¹ï¸ æœªæ‰¾åˆ°é…ç½®æª”æ¡ˆï¼Œè¼‰å…¥é è¨­é…ç½®")
        app_config = DEFAULT_CONFIG.copy()

def save_config():
    """Saves current configuration to config.json."""
    global app_config
    try:
        with open(CONFIG_FILE, "w", encoding="utf-8") as f:
            # Json dump will handle escaping newlines
            json.dump(app_config, f, indent=4, ensure_ascii=False) # ensure_ascii=False keeps non-ASCII chars readable
        print("âœ… é…ç½®å„²å­˜æˆåŠŸ")
    except IOError as e:
        messagebox.showerror("å„²å­˜éŒ¯èª¤", f"ç„¡æ³•å„²å­˜é…ç½®æª”æ¡ˆ: {e}")
    except Exception as e:
         messagebox.showerror("å„²å­˜éŒ¯èª¤", f"å„²å­˜é…ç½®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
         traceback.print_exc()


# --- GUI Elements ---
class SettingsWindow(tk.Toplevel):
    """GUI window for application settings."""
    def __init__(self, parent):
        super().__init__(parent)
        self.title("è¨­å®š")
        # Adjust geometry to accommodate prompt text area
        self.geometry("600x700")
        self.transient(parent) # Keep window on top of the parent
        self.grab_set() # Modal window - blocks interaction with parent window

        # Create a main frame for padding and organization
        main_frame = tk.Frame(self)
        main_frame.pack(pady=10, padx=10, fill=tk.BOTH, expand=True)

        # --- Variables ---
        self.llm_type_var = tk.StringVar(value=app_config.get("llm_type", "gpt"))
        self.gpt_key_var = tk.StringVar(value=app_config.get("gpt_api_key", ""))
        self.gpt_model_var = tk.StringVar(value=app_config.get("gpt_model_name", "gpt-4o-mini"))
        self.ollama_base_var = tk.StringVar(value=app_config.get("ollama_api_base", "http://localhost:11434/v1"))
        self.ollama_model_var = tk.StringVar(value=app_config.get("ollama_model_name", "llama3"))
        self.ffmpeg_path_var = tk.StringVar(value=app_config.get("ffmpeg_path", DEFAULT_CONFIG["ffmpeg_path"])) # Use default from config for OS awareness
        self.whisper_model_var = tk.StringVar(value=app_config.get("whisper_model", "small"))
        self.buffer_time_var = tk.DoubleVar(value=app_config.get("buffer_time", 0.5))
        self.min_duration_var = tk.DoubleVar(value=app_config.get("min_duration", 2.0))
        # Prompt template will be handled directly with the text widget


        # --- LLM Selection ---
        llm_frame = tk.LabelFrame(main_frame, text="å¤§å‹èªè¨€æ¨¡å‹ (LLM) è¨­å®š")
        llm_frame.pack(pady=5, fill=tk.X)

        tk.Label(llm_frame, text="é¸æ“‡ LLM:").pack(side=tk.LEFT, padx=5)
        tk.Radiobutton(llm_frame, text="OpenAI GPT", variable=self.llm_type_var, value="gpt", command=self._update_fields).pack(side=tk.LEFT, padx=5)
        tk.Radiobutton(llm_frame, text="Ollama", variable=self.llm_type_var, value="ollama", command=self._update_fields).pack(side=tk.LEFT, padx=5)


        # --- GPT Settings ---
        self.gpt_frame = tk.LabelFrame(main_frame, text="OpenAI GPT è¨­å®š")
        self.gpt_frame.pack(pady=5, fill=tk.X)

        tk.Label(self.gpt_frame, text="API Key:").pack(side=tk.LEFT, padx=5)
        tk.Entry(self.gpt_frame, textvariable=self.gpt_key_var, width=30, show='*').pack(side=tk.LEFT, padx=5, expand=True, fill=tk.X)
        tk.Label(self.gpt_frame, text="Model:").pack(side=tk.LEFT, padx=5)
        tk.Entry(self.gpt_frame, textvariable=self.gpt_model_var, width=15).pack(side=tk.LEFT, padx=5)

        # --- Ollama Settings ---
        self.ollama_frame = tk.LabelFrame(main_frame, text="Ollama è¨­å®š")
        self.ollama_frame.pack(pady=5, fill=tk.X)

        tk.Label(self.ollama_frame, text="API Base URL:").pack(side=tk.LEFT, padx=5)
        tk.Entry(self.ollama_frame, textvariable=self.ollama_base_var, width=30).pack(side=tk.LEFT, padx=5, expand=True, fill=tk.X)
        tk.Label(self.ollama_frame, text="Model:").pack(side=tk.LEFT, padx=5)
        tk.Entry(self.ollama_frame, textvariable=self.ollama_model_var, width=15).pack(side=tk.LEFT, padx=5)


        # --- Other Settings ---
        other_frame = tk.LabelFrame(main_frame, text="å…¶ä»–è¨­å®š")
        other_frame.pack(pady=5, fill=tk.X)

        tk.Label(other_frame, text="FFmpeg è·¯å¾‘:").pack(side=tk.LEFT, padx=5)
        tk.Entry(other_frame, textvariable=self.ffmpeg_path_var, width=30).pack(side=tk.LEFT, padx=5, expand=True, fill=tk.X)
        tk.Button(other_frame, text="ç€è¦½", command=self._select_ffmpeg).pack(side=tk.LEFT, padx=5)

        tk.Label(other_frame, text="Whisper Model:").pack(side=tk.LEFT, padx=(15,5))
        tk.Entry(other_frame, textvariable=self.whisper_model_var, width=10).pack(side=tk.LEFT, padx=5)

        # Buffer and Duration settings
        timing_frame = tk.Frame(other_frame)
        timing_frame.pack(pady=5, fill=tk.X)
        tk.Label(timing_frame, text="ç·©è¡æ™‚é–“ (ç§’):").pack(side=tk.LEFT, padx=5)
        tk.Entry(timing_frame, textvariable=self.buffer_time_var, width=8).pack(side=tk.LEFT, padx=5)
        tk.Label(timing_frame, text="æœ€å°ç‰‡æ®µæ™‚é•· (ç§’):").pack(side=tk.LEFT, padx=5)
        tk.Entry(timing_frame, textvariable=self.min_duration_var, width=8).pack(side=tk.LEFT, padx=5)

        # --- AI Prompt Template Setting ---
        prompt_frame = tk.LabelFrame(main_frame, text="AI æç¤ºè©æ¨¡æ¿è¨­å®š (ä½¿ç”¨ {subtitle_content} æ’å…¥å­—å¹•)")
        prompt_frame.pack(pady=5, fill=tk.BOTH, expand=True) # Allow this frame to expand

        self.prompt_text = scrolledtext.ScrolledText(prompt_frame, wrap=tk.WORD, width=70, height=10)
        self.prompt_text.pack(pady=5, padx=5, fill=tk.BOTH, expand=True)

        # Load current prompt template into the text widget
        current_prompt_template = app_config.get("ai_prompt_template", DEFAULT_AI_PROMPT_TEMPLATE)
        self.prompt_text.insert(tk.END, current_prompt_template)


        # --- Save Button ---
        tk.Button(main_frame, text="å„²å­˜è¨­å®š", command=self._save_and_close).pack(pady=10)

        self._update_fields() # Initialize field states


    def _update_fields(self):
        """Enables/disables LLM specific fields based on selection."""
        llm_type = self.llm_type_var.get()
        if llm_type == "gpt":
            for child in self.gpt_frame.winfo_children():
                 child.config(state=tk.NORMAL)
            for child in self.ollama_frame.winfo_children():
                 child.config(state=tk.DISABLED)
        else: # ollama
            for child in self.gpt_frame.winfo_children():
                 child.config(state=tk.DISABLED)
            for child in self.ollama_frame.winfo_children():
                 child.config(state=tk.NORMAL)

    def _select_ffmpeg(self):
        """Opens file dialog to select FFmpeg executable."""
        path = filedialog.askopenfilename(title="é¸æ“‡ FFmpeg åŸ·è¡Œæª”", filetypes=[("Executables", "*.exe;*"), ("All files", "*.*")])
        if path:
            self.ffmpeg_path_var.set(path)

    def _save_and_close(self):
        """Saves settings and closes the window."""
        global app_config
        try:
            # Attempt to get values, will raise ValueError for non-numeric input
            buffer_time = self.buffer_time_var.get()
            min_duration = self.min_duration_var.get()
            prompt_template = self.prompt_text.get("1.0", tk.END).strip() # Get text from ScrolledText

            # Basic validation for prompt template
            if "{subtitle_content}" not in prompt_template:
                 messagebox.showwarning("æç¤ºè©è­¦å‘Š", "æç¤ºè©æ¨¡æ¿ä¸­æœªåŒ…å«ä½”ä½ç¬¦ {subtitle_content}ï¼Œå­—å¹•å…§å®¹å°‡ç„¡æ³•æ’å…¥ã€‚")
                 # Decide if we should allow saving or force correction
                 # For now, allow saving but warn.

            app_config["llm_type"] = self.llm_type_var.get()
            app_config["gpt_api_key"] = self.gpt_key_var.get()
            app_config["gpt_model_name"] = self.gpt_model_var.get()
            app_config["ollama_api_base"] = self.ollama_base_var.get()
            app_config["ollama_model_name"] = self.ollama_model_var.get()
            app_config["ffmpeg_path"] = self.ffmpeg_path_var.get()
            app_config["whisper_model"] = self.whisper_model_var.get()
            app_config["buffer_time"] = buffer_time
            app_config["min_duration"] = min_duration
            app_config["ai_prompt_template"] = prompt_template


            save_config()
            self.destroy()
        except ValueError:
             messagebox.showerror("è¼¸å…¥éŒ¯èª¤", "ç·©è¡æ™‚é–“å’Œæœ€å°ç‰‡æ®µæ™‚é•·å¿…é ˆæ˜¯æœ‰æ•ˆçš„æ•¸å­—")
        except Exception as e:
             messagebox.showerror("å„²å­˜éŒ¯èª¤", f"å„²å­˜è¨­å®šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
             traceback.print_exc()


class SubtitleEditorWindow(tk.Toplevel):
    """GUI window for editing subtitles."""
    def __init__(self, parent, subtitles_text, save_callback):
        super().__init__(parent)
        self.title("ç·¨è¼¯å­—å¹•")
        self.geometry("700x500")
        self.transient(parent)
        self.grab_set()

        self.save_callback = save_callback

        tk.Label(self, text="è«‹ç·¨è¼¯å­—å¹•å…§å®¹ï¼š").pack(pady=5)
        # Use ScrolledText for better handling of large text
        self.text_area = scrolledtext.ScrolledText(self, wrap=tk.WORD, width=80, height=25)
        self.text_area.insert(tk.END, subtitles_text)
        self.text_area.pack(pady=10, padx=10, expand=True, fill=tk.BOTH)

        tk.Button(self, text="å„²å­˜ä¸¦ç¹¼çºŒ", command=self._save_and_close).pack(pady=10)

    def _save_and_close(self):
        """Gets edited text and calls the save callback."""
        edited_text = self.text_area.get("1.0", tk.END).strip()
        self.save_callback(edited_text)
        self.destroy()

# --- LLM Abstraction ---
def call_llm(prompt):
    """Calls the selected LLM with the given prompt."""
    llm_type = app_config.get("llm_type", "gpt")
    model_name = (app_config.get("gpt_model_name") if llm_type == "gpt"
                  else app_config.get("ollama_model_name"))

    print(f"ğŸ¤– å‘¼å« {llm_type.upper()} æ¨¡å‹ï¼š{model_name}")

    try:
        if llm_type == "gpt":
            api_key = app_config.get("gpt_api_key")
            if not api_key:
                # Use root.after for messagebox from thread
                # messagebox.showerror("LLM è¨­å®šéŒ¯èª¤", "è«‹åœ¨è¨­å®šä¸­è¼¸å…¥ GPT API Key")
                return None
            client = OpenAI(api_key=api_key)
            response = client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å½±ç‰‡å‰ªè¼¯åŠ©æ‰‹ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3
            )
            return response.choices[0].message.content
        elif llm_type == "ollama":
            api_base = app_config.get("ollama_api_base")
            if not api_base:
                 # Use root.after for messagebox from thread
                 # messagebox.showerror("LLM è¨­å®šéŒ¯èª¤", "è«‹åœ¨è¨­å®šä¸­è¼¸å…¥ Ollama API Base URL")
                 return None
            # Use OpenAI compatible API for Ollama
            # Ensure Ollama is running and the model is available
            try:
                client = OpenAI(base_url=api_base, api_key="not-needed") # API key is ignored by Ollama
                response = client.chat.completions.create(
                    model=model_name,
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å½±ç‰‡å‰ªè¼¯åŠ©æ‰‹ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                     temperature=0.3 # Ollama might not support all parameters
                     # Ollama might not support all OpenAI parameters, temperature is usually ok
                )
                return response.choices[0].message.content
            except Exception as ollama_e:
                # Use root.after for messagebox from thread
                # messagebox.showerror("Ollama éŒ¯èª¤", f"å‘¼å« Ollama å¤±æ•—ï¼Œè«‹æª¢æŸ¥ Ollama æ˜¯å¦æ­£åœ¨é‹è¡Œä»¥åŠ API Base URL å’Œæ¨¡å‹åç¨±æ˜¯å¦æ­£ç¢ºã€‚\néŒ¯èª¤: {ollama_e}")
                print(f"âŒ Ollama å‘¼å«å¤±æ•—: {ollama_e}")
                traceback.print_exc()
                return None
        else:
            # Use root.after for messagebox from thread
            # messagebox.showerror("LLM è¨­å®šéŒ¯èª¤", f"æœªçŸ¥çš„ LLM é¡å‹: {llm_type}")
            return None

    except Exception as e:
        # Use root.after for messagebox from thread
        # messagebox.showerror("LLM å‘¼å«éŒ¯èª¤", f"å‘¼å« {llm_type.upper()} å¤±æ•—: {e}")
        print(f"âŒ LLM å‘¼å«å¤±æ•—: {e}")
        traceback.print_exc()
        return None

# --- Helper function for time formatting ---
def format_timedelta_srt(td: timedelta) -> str:
    """Formats a timedelta object into an SRT time string (HH:MM:SS,ms)."""
    total_seconds = int(td.total_seconds())
    hours, remainder = divmod(total_seconds, 3600)
    minutes, seconds = divmod(remainder, 60)
    milliseconds = td.microseconds // 1000
    # Ensure milliseconds are exactly 3 digits
    return f"{hours:02d}:{minutes:02d}:{seconds:02d},{milliseconds:03d}"

# Helper function to convert HH:MM:SS.ms string to total seconds
def hms_to_sec(hms: str) -> float:
    """Converts HH:MM:SS.ms string to total seconds."""
    try:
        # Handle potential HH:MM:SS format without milliseconds
        if '.' not in hms:
            hms += '.000'
        h, m, s_m = hms.split(":")
        s, mmm = s_m.split(".")
        return float(h) * 3600 + float(m) * 60 + float(s) + float(mmm) / 1000.0
    except ValueError as e:
        print(f"âš ï¸ æ™‚é–“æ ¼å¼è½‰æ›éŒ¯èª¤ï¼š{hms} -> {e}")
        traceback.print_exc()
        return 0.0 # Return 0 or handle error appropriately


# --- Main Application Logic ---
class VideoEditorApp:
    """Main application class to manage workflow and GUI."""
    def __init__(self, root):
        self.root = root
        self.root.title("AI å½±ç‰‡å‰ªè¼¯åŠ©æ‰‹")
        self.root.geometry("300x150")
        self.root.resizable(False, False) # Prevent resizing the main window

        self.video_path = None
        self.original_srt_path = None
        self.merged_video_path = None
        self.final_srt_path = None
        self.temp_clips = [] # List to store temporary clip paths

        load_config() # Load configuration at startup

        # --- Main Window Buttons ---
        tk.Button(self.root, text="è¨­å®š", command=self.open_settings).pack(pady=10)
        tk.Button(self.root, text="é¸æ“‡å½±ç‰‡ä¸¦é–‹å§‹è™•ç†", command=self.start_processing_workflow).pack(pady=10)
        tk.Button(self.root, text="é›¢é–‹", command=self.root.quit).pack(pady=10)

        # Status label (optional, can add to show progress)
        # self.status_label = tk.Label(self.root, text="ç­‰å¾…æ“ä½œ...")
        # self.status_label.pack(pady=5)


    def open_settings(self):
        """Opens the settings window."""
        SettingsWindow(self.root)
        # Config will be reloaded in check_configuration or start_processing_workflow
        # after the settings window is closed and saved.


    def check_configuration(self):
        """Checks if essential configuration is valid before starting processing."""
        load_config() # Always reload config to get potential changes from settings window

        self.ffmpeg_path = app_config.get("ffmpeg_path")
        if not self.ffmpeg_path or not os.path.exists(self.ffmpeg_path):
            self.root.after(0, messagebox.showerror, "é…ç½®éŒ¯èª¤", "FFmpeg è·¯å¾‘ç„¡æ•ˆï¼Œè«‹å…ˆé€²å…¥è¨­å®šé é¢é…ç½®æ­£ç¢ºçš„è·¯å¾‘ã€‚")
            print("âŒ FFmpeg è·¯å¾‘ç„¡æ•ˆ")
            return False

        llm_type = app_config.get("llm_type")
        if llm_type == "gpt":
            if not app_config.get("gpt_api_key"):
                 self.root.after(0, messagebox.showerror, "é…ç½®éŒ¯èª¤", "å·²é¸æ“‡ GPT ä½œç‚º LLMï¼Œä½†æœªé…ç½® API Keyã€‚è«‹å…ˆé€²å…¥è¨­å®šé é¢é…ç½®ã€‚")
                 print("âŒ GPT API Key æœªé…ç½®")
                 return False
        elif llm_type == "ollama":
             if not app_config.get("ollama_api_base") or not app_config.get("ollama_model_name"):
                 self.root.after(0, messagebox.showerror, "é…ç½®éŒ¯èª¤", "å·²é¸æ“‡ Ollama ä½œç‚º LLMï¼Œä½†æœªé…ç½® API Base URL æˆ– æ¨¡å‹åç¨±ã€‚è«‹å…ˆé€²å…¥è¨­å®šé é¢é…ç½®ã€‚")
                 print("âŒ Ollama é…ç½®ä¸å®Œæ•´")
                 return False
        else:
             self.root.after(0, messagebox.showerror, "é…ç½®éŒ¯èª¤", f"æœªçŸ¥çš„ LLM é¡å‹ '{llm_type}'ã€‚è«‹æª¢æŸ¥è¨­å®šã€‚")
             print(f"âŒ æœªçŸ¥ LLM é¡å‹: {llm_type}")
             return False

        # Check if prompt template placeholder exists
        prompt_template = app_config.get("ai_prompt_template", "")
        if "{subtitle_content}" not in prompt_template:
             self.root.after(0, messagebox.showerror, "é…ç½®éŒ¯èª¤", "AI æç¤ºè©æ¨¡æ¿ä¸­æœªåŒ…å«å¿…è¦çš„ä½”ä½ç¬¦ {subtitle_content}ã€‚è«‹ä¿®æ”¹è¨­å®šã€‚")
             print("âŒ AI æç¤ºè©æ¨¡æ¿ç¼ºå°‘ä½”ä½ç¬¦")
             return False


        self.output_dir = app_config.get("output_dir", "out")
        os.makedirs(self.output_dir, exist_ok=True)

        print("âœ… é…ç½®æª¢æŸ¥é€šé")
        return True


    def start_processing_workflow(self):
        """Initiates the video selection and processing workflow."""
        # Check configuration before proceeding
        if not self.check_configuration():
            return # Stop if config is invalid

        # Start the rest of the workflow in a separate thread
        threading.Thread(target=self._processing_workflow_thread).start()


    def _processing_workflow_thread(self):
        """The main processing workflow run in a separate thread."""
        self.select_video() # This will call generate_subtitles_if_needed etc if a video is selected


    def select_video(self):
        """Opens file dialog to select the video."""
        # filedialog must be called from the main thread or a thread that has a Tk context.
        # Since start_processing_workflow is called from the main thread, and then this method
        # is called from the new thread, we need to use root.after to run file dialog in main thread.
        self.root.after(0, self._select_video_in_main_thread)

    def _select_video_in_main_thread(self):
        """Handles video selection in the main GUI thread."""
        self.video_path = filedialog.askopenfilename(title="é¸æ“‡è¦å‰ªè¼¯çš„å½±ç‰‡", filetypes=[("MP4 Files", "*.mp4")])
        if not self.video_path:
            self.root.after(0, messagebox.showinfo, "å–æ¶ˆ", "æœªé¸æ“‡å½±ç‰‡ï¼Œè™•ç†æµç¨‹çµæŸ")
            print("âŒ æœªé¸æ“‡å½±ç‰‡")
            return

        video_basename = os.path.splitext(os.path.basename(self.video_path))[0]
        # Assume original SRT is in the same directory as the video
        self.original_srt_path = os.path.join(os.path.dirname(self.video_path), video_basename + ".srt")
        self.merged_video_path = os.path.join(self.output_dir, "final_merged.mp4") # Changed name to avoid overwriting potential final output
        self.final_srt_path = os.path.join(self.output_dir, "final_merged.srt") # SRT for the merged video

        # Resume the processing workflow in the background thread
        threading.Thread(target=self._resume_processing_after_select).start()

    def _resume_processing_after_select(self):
         """Continues the workflow after video selection."""
         # Ensure necessary paths are set
         if not self.video_path:
              print("âŒ æœªé¸æ“‡å½±ç‰‡ï¼Œç„¡æ³•ç¹¼çºŒè™•ç†ã€‚")
              return

         self.generate_subtitles_if_needed()


    # --- The following methods are the core processing steps ---
    # They will be called sequentially (or triggered by user action like saving subtitles)

    def generate_subtitles_if_needed(self):
        """Generates initial SRT using Whisper if it doesn't exist."""
        # Use print statements for console feedback, maybe update a status label in GUI
        print("ğŸ” æª¢æŸ¥åŸå§‹å½±ç‰‡å­—å¹•...")
        if not os.path.exists(self.original_srt_path):
            print("ğŸ” æœªæ‰¾åˆ°åŸå§‹å½±ç‰‡å­—å¹•ï¼Œä½¿ç”¨ Whisper ç”¢ç”Ÿä¸­...")
            try:
                whisper_model_name = app_config.get("whisper_model", "small")
                print(f"âœ¨ ä½¿ç”¨ Whisper æ¨¡å‹ï¼š{whisper_model_name}")
                model = whisper.load_model(whisper_model_name)
                print("è½‰éŒ„ä¸­ï¼Œé€™å¯èƒ½éœ€è¦ä¸€æ®µæ™‚é–“...")
                # Pass video_path directly to transcribe
                # Use root.after for any messagebox calls from this thread
                result = model.transcribe(self.video_path, fp16=False, language="zh")

                with open(self.original_srt_path, "w", encoding="utf-8") as f:
                    for i, segment in enumerate(result["segments"]):
                        start_td = timedelta(seconds=segment['start'])
                        end_td = timedelta(seconds=segment['end'])
                        f.write(f"{i+1}\n{format_timedelta_srt(start_td)} --> {format_timedelta_srt(end_td)}\n{segment['text'].strip()}\n\n")
                print(f"âœ… åŸå§‹å½±ç‰‡å­—å¹•ç”¢ç”Ÿå®Œæˆï¼š{self.original_srt_path}")
            except Exception as e:
                # Use self.root.after to show error message from thread in main GUI thread
                self.root.after(0, messagebox.showerror, "Whisper éŒ¯èª¤", f"åŸå§‹å½±ç‰‡å­—å¹•ç”¢ç”Ÿå¤±æ•—: {e}")
                print(f"âŒ åŸå§‹å½±ç‰‡å­—å¹•ç”¢ç”Ÿå¤±æ•—: {e}")
                traceback.print_exc() # Print detailed error info
                # Decide how to handle fatal errors - maybe go back to main window or quit
                return

        # Proceed after ensuring original SRT exists
        self.process_with_llm()

    def process_with_llm(self):
        """Reads subtitles, creates prompt, calls LLM, and initiates clipping."""
        print("ğŸ¤– æº–å‚™å‘¼å« LLM åˆ†æå­—å¹•...")
        try:
            with open(self.original_srt_path, "r", encoding="utf-8") as f:
                subs = list(srt.parse(f.read()))
        except FileNotFoundError:
            self.root.after(0, messagebox.showerror, "æª”æ¡ˆéŒ¯èª¤", f"åŸå§‹å­—å¹•æª”æ¡ˆæœªæ‰¾åˆ°: {self.original_srt_path}")
            print(f"âŒ åŸå§‹å­—å¹•æª”æ¡ˆæœªæ‰¾åˆ°: {self.original_srt_path}")
            return
        except Exception as e:
            self.root.after(0, messagebox.showerror, "è®€å–éŒ¯èª¤", f"è®€å–åŸå§‹å­—å¹•æª”æ¡ˆå¤±æ•—: {e}")
            print(f"âŒ è®€å–åŸå§‹å­—å¹•æª”æ¡ˆå¤±æ•—: {e}")
            return


        å­—å¹•å…§å®¹ = ""
        for sub in subs:
            # Format timedelta to match expected prompt format (HH:MM:SS.ms)
            start_td = sub.start
            end_td = sub.end
            # Use total_seconds for accurate floating point representation
            start_sec = start_td.total_seconds()
            end_sec = end_td.total_seconds()
            start_str = f"{int(start_sec // 3600):02}:{int((start_sec % 3600) // 60):02}:{start_sec % 60:06.3f}"
            end_str = f"{int(end_sec // 3600):02}:{int((end_sec % 3600) // 60):02}:{end_sec % 60:06.3f}"
            å­—å¹•å…§å®¹ += f"[{start_str} - {end_str}] {sub.content.strip()}\n"

        # --- Use the configurable AI Prompt Template ---
        prompt_template = app_config.get("ai_prompt_template", DEFAULT_AI_PROMPT_TEMPLATE)

        # Basic check for placeholder (should be done in config check, but double check)
        if "{subtitle_content}" not in prompt_template:
             self.root.after(0, messagebox.showerror, "æç¤ºè©éŒ¯èª¤", "é…ç½®ä¸­çš„ AI æç¤ºè©æ¨¡æ¿ç¼ºå°‘å¿…è¦çš„ä½”ä½ç¬¦ {subtitle_content}ã€‚è«‹æª¢æŸ¥è¨­å®šã€‚")
             print("âŒ AI æç¤ºè©æ¨¡æ¿ç¼ºå°‘ä½”ä½ç¬¦ï¼Œç„¡æ³•ç”Ÿæˆæœ‰æ•ˆæç¤ºã€‚")
             return

        try:
            # Format the final prompt by inserting the subtitle content
            ai_prompt = prompt_template.format(subtitle_content=å­—å¹•å…§å®¹)
        except Exception as e:
            self.root.after(0, messagebox.showerror, "æç¤ºè©æ ¼å¼éŒ¯èª¤", f"æ ¼å¼åŒ– AI æç¤ºè©å¤±æ•—: {e}ã€‚è«‹æª¢æŸ¥æç¤ºè©æ¨¡æ¿èªæ³•ã€‚")
            print(f"âŒ æ ¼å¼åŒ– AI æç¤ºè©å¤±æ•—: {e}")
            traceback.print_exc()
            return


        ai_reply = call_llm(ai_prompt) # This call might block the thread

        if not ai_reply:
            # call_llm already shows error message
            print("âŒ å¾ LLM ç²å¾—ç„¡æ•ˆå›è¦†")
            return

        print("ğŸ¤– AI å›æ‡‰å¦‚ä¸‹ï¼š\n", ai_reply)

        # --- START: Integrate time range processing from 4o.py ---
        print("â³ è™•ç† AI å›æ‡‰æ™‚é–“æ®µï¼Œåˆä½µé‡ç–Š/ç›¸è¿‘å€æ®µ...")
        matches = re.findall(r'(\d{2}:\d{2}:\d{2}\.\d{3})\s*-\s*(\d{2}:\d{2}:\d{2}\.\d{3})', ai_reply)

        if not matches:
            self.root.after(0, messagebox.showwarning, "AI è­¦å‘Š", "AI æ²’æœ‰å›å‚³ä»»ä½•æœ‰æ•ˆç‰‡æ®µæ™‚é–“ç¯„åœã€‚è«‹æª¢æŸ¥ LLM å›æ‡‰æ ¼å¼æ˜¯å¦æ­£ç¢ºã€‚")
            print("âš ï¸ AI æ²’æœ‰å›å‚³ä»»ä½•æœ‰æ•ˆç‰‡æ®µ")
            return

        # Sort matches by start time
        matches = sorted(matches, key=lambda x: hms_to_sec(x[0]))

        buffered_ranges = []
        buffer_time = app_config.get("buffer_time", 0.5)
        for start_str, end_str in matches:
            start_sec = max(0, hms_to_sec(start_str) - buffer_time)
            end_sec = hms_to_sec(end_str) + buffer_time
            if end_sec > start_sec: # Ensure end is after start after buffering
                buffered_ranges.append([start_sec, end_sec])

        # Sort buffered ranges by start time (redundant if matches were sorted, but safe)
        buffered_ranges = sorted(buffered_ranges, key=lambda x: x[0])

        merged_ranges = []
        merge_gap = 0.5 # Gap for merging adjacent clips (can be added to config later)
        for start, end in buffered_ranges:
            # Merge overlapping or adjacent (gap <= merge_gap) segments
            if not merged_ranges or start > merged_ranges[-1][1] + merge_gap:
                merged_ranges.append([start, end])
            else:
                # Extend the end time of the last merged range
                merged_ranges[-1][1] = max(merged_ranges[-1][1], end)

        # Filter merged ranges by minimum duration
        min_duration = app_config.get("min_duration", 2.0)
        final_clip_ranges = [[start, end] for start, end in merged_ranges if end - start >= min_duration]

        if not final_clip_ranges:
            self.root.after(0, messagebox.showwarning, "å‰ªè¼¯è­¦å‘Š", "ç¶“éè™•ç†èˆ‡åˆä½µå¾Œï¼Œæ²’æœ‰ç¬¦åˆæœ€å°æ™‚é•·æ¢ä»¶çš„å‰ªè¼¯ç‰‡æ®µã€‚è«‹æª¢æŸ¥ AI å›æ‡‰æˆ–èª¿æ•´è¨­å®š (ç·©è¡æ™‚é–“/æœ€å°æ™‚é•·)ã€‚")
            print("âŒ ç¶“éè™•ç†å¾Œï¼Œæ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å‰ªè¼¯ç‰‡æ®µ")
            return

        print(f"âœ… è™•ç†å¾Œå¾—åˆ° {len(final_clip_ranges)} å€‹ä¸é‡ç–Šçš„å‰ªè¼¯æ™‚é–“æ®µã€‚")

        # --- END: Integrate time range processing from 4o.py ---


        self.clip_videos(final_clip_ranges) # Pass the final processed ranges


    def clip_videos(self, clip_ranges):
        """Clips video segments based on the processed ranges."""
        clip_list_path = os.path.join(self.output_dir, "list.txt")
        # Clear or create list.txt before clipping
        with open(clip_list_path, "w", encoding="utf-8") as list_file:
            pass

        print("âœ‚ï¸ é–‹å§‹å‰ªè¼¯ç‰‡æ®µ...")
        self.temp_clips = [] # Reset temp clips list for the new batch of clips
        successful_clips_count = 0

        # Iterate over the final_clip_ranges (merged and filtered)
        for i, (start, end) in enumerate(clip_ranges):
            duration = end - start
            clip_name = f"clip_{i:03d}.mp4"
            output_clip = os.path.join(self.output_dir, clip_name)
            # temp_clips will track all intended clip paths for cleanup
            self.temp_clips.append(output_clip)

            # FFmpeg command to clip - Using parameters from 4o.py
            # -ss and -t BEFORE -i, plus timestamp reset flags
            cmd = [
                self.ffmpeg_path,
                "-ss", f"{start:.3f}", # Start time (seconds, .ms)
                "-t",  f"{duration:.3f}", # Duration (seconds, .ms)
                "-i",  self.video_path,  # Input original video
                "-reset_timestamps", "1", # Reset timestamps to start from 0
                "-avoid_negative_ts", "make_zero", # Handle potential negative timestamps
                "-c:v", "copy", # Copy video stream (no re-encoding)
                "-c:a", "copy", # Copy audio stream (no re-encoding)
                output_clip,
                "-y" # Overwrite output file without asking
            ]
            print(f"Â  - å‰ªè¼¯ {clip_name} (æ™‚é–“æ®µ: {start:.3f}s - {end:.3f}s, æ™‚é•·: {duration:.3f}s)")

            try:
                # Adding creationflags=subprocess.CREATE_NO_WINDOW hides console window on Windows
                # Use capture_output=True and text=True with encoding="utf-8" for better error handling
                # Need to ensure this doesn't block the main thread if run directly
                # This method is called from a background thread, so subprocess.run is OK here.
                process = subprocess.run(cmd, capture_output=True, text=True, encoding="utf-8", creationflags=subprocess.CREATE_NO_WINDOW if os.name == 'nt' else 0)

                if process.returncode != 0:
                    print(f"âŒ FFmpeg å‰ªè¼¯ {clip_name} å¤±æ•— (è¿”å›ç¢¼: {process.returncode}):")
                    print(process.stderr) # stderr is already text=True and decoded as utf-8
                    self.root.after(0, messagebox.showwarning, "å‰ªè¼¯å¤±æ•—", f"å‰ªè¼¯ç‰‡æ®µ {clip_name} å¤±æ•—ï¼Œè«‹æª¢æŸ¥æ§åˆ¶å°è¼¸å‡ºã€‚\néŒ¯èª¤ç¢¼: {process.returncode}")
                    # Do NOT write to list.txt if failed
                else:
                    # Clip succeeded, append to list.txt
                    with open(clip_list_path, "a", encoding="utf-8") as list_file:
                         list_file.write(f"file '{os.path.basename(output_clip)}'\n") # Write just the filename
                    successful_clips_count += 1


            except Exception as e:
                print(f"âŒ å‰ªè¼¯ç‰‡æ®µ {i+1} éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
                traceback.print_exc() # Print detailed error info
                self.root.after(0, messagebox.showwarning, "å‰ªè¼¯éŒ¯èª¤", f"å‰ªè¼¯ç‰‡æ®µ {clip_name} éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
                # Continue to the next clip

        # After the loop, check if any clips were successfully added to the list
        if successful_clips_count == 0 or not os.path.exists(clip_list_path) or os.stat(clip_list_path).st_size == 0:
            self.root.after(0, messagebox.showwarning, "å‰ªè¼¯è­¦å‘Š", "æ²’æœ‰æˆåŠŸç”Ÿæˆä»»ä½•å‰ªè¼¯ç‰‡æ®µï¼Œç„¡æ³•åˆä½µã€‚è«‹æª¢æŸ¥æ§åˆ¶å°è¼¸å‡ºçš„éŒ¯èª¤è¨Šæ¯ã€‚")
            print("âš ï¸ æ²’æœ‰æˆåŠŸç”Ÿæˆä»»ä½•å‰ªè¼¯ç‰‡æ®µï¼Œç„¡æ³•åˆä½µã€‚")
            self.cleanup_temp_clips() # Clean up any partially created files
        else:
            print(f"âœ… æˆåŠŸç”Ÿæˆ {successful_clips_count} å€‹å‰ªè¼¯ç‰‡æ®µã€‚")
            self.concatenate_clips(clip_list_path) # Proceed to concatenate


    def concatenate_clips(self, clip_list_path):
        """Concatenates the clipped video segments."""
        print("ğŸš€ åˆä½µå‰ªè¼¯ç‰‡æ®µä¸­...")
        # Ensure clip_list_path exists and is not empty before trying to concat
        if not os.path.exists(clip_list_path) or os.stat(clip_list_path).st_size == 0:
            print("âŒ åˆä½µåˆ—è¡¨æª”æ¡ˆä¸å­˜åœ¨æˆ–ç‚ºç©ºï¼Œè·³éåˆä½µã€‚")
            # Need to decide what to do if concat list is unexpectedly empty here
            # Probably just stop the process flow for this video.
            self.cleanup_temp_clips() # Clean up any partial clips
            return

        self.merged_video_path = os.path.join(self.output_dir, "final_merged.mp4") # Ensure path is set

        cmd_concat = [
            self.ffmpeg_path, "-f", "concat", "-safe", "0",
            "-i", clip_list_path,
            "-c:v", "copy", "-c:a", "copy",
            self.merged_video_path,
            "-y" # Overwrite output file without asking
        ]
        try:
            # Adding creationflags=subprocess.CREATE_NO_WINDOW hides console window on Windows
            # Use capture_output=True and text=True with encoding="utf-8" for better error handling
            # This is called from a background thread, subprocess.run is OK.
            process_concat = subprocess.run(cmd_concat, check=True, capture_output=True, text=True, encoding="utf-8", creationflags=subprocess.CREATE_NO_WINDOW if os.name == 'nt' else 0)
            print(f"ğŸ‰ åˆä½µå®Œæˆï¼è¼¸å‡ºå½±ç‰‡ï¼š{self.merged_video_path}")

            # Only cleanup temp clips if concatenation was successful
            self.cleanup_temp_clips()

            # Proceed to generate subtitles for the merged video
            self.generate_final_subtitles()

        except subprocess.CalledProcessError as e:
             self.root.after(0, messagebox.showerror, "FFmpeg åˆä½µéŒ¯èª¤", f"åˆä½µå¤±æ•— (è¿”å›ç¢¼: {e.returncode}):\n{e.stderr}")
             print(f"âŒ åˆä½µå¤±æ•— (è¿”å›ç¢¼: {e.returncode}):\n{e.stderr}")
             traceback.print_exc() # Print detailed error info
             self.cleanup_temp_clips() # Clean up temp clips even if concat failed
        except Exception as e:
             self.root.after(0, messagebox.showerror, "åˆä½µéŒ¯èª¤", f"åˆä½µéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
             print(f"âŒ åˆä½µéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
             traceback.print_exc() # Print detailed error info
             self.cleanup_temp_clips() # Clean up temp clips

    # --- The rest of the methods (generate_final_subtitles, show_subtitle_editor,
    # save_edited_subtitles, prompt_final_merge, embed_subtitles_to_video, cleanup_temp_clips)
    # remain largely the same ---


    def generate_final_subtitles(self):
        """Generates new subtitles for the merged video."""
        print("ğŸ” ç‚ºåˆä½µå¾Œçš„å½±ç‰‡ç”¢ç”Ÿæ–°å­—å¹•...")
        if not os.path.exists(self.merged_video_path):
             self.root.after(0, messagebox.showerror, "æª”æ¡ˆéŒ¯èª¤", f"åˆä½µå¾Œçš„å½±ç‰‡æœªæ‰¾åˆ°: {self.merged_video_path}")
             print(f"âŒ åˆä½µå¾Œçš„å½±ç‰‡æœªæ‰¾åˆ°: {self.merged_video_path}")
             return

        try:
            whisper_model_name = app_config.get("whisper_model", "small")
            print(f"âœ¨ ä½¿ç”¨ Whisper æ¨¡å‹ï¼š{whisper_model_name}")
            model = whisper.load_model(whisper_model_name)
            print("è½‰éŒ„åˆä½µå¾Œå½±ç‰‡ä¸­ï¼Œé€™å¯èƒ½éœ€è¦ä¸€æ®µæ™‚é–“...")
            # Transcribe the merged video
            # Use root.after for any messagebox calls from this thread
            result = model.transcribe(self.merged_video_path, fp16=False, language="zh")

            final_srt_content = ""
            for i, segment in enumerate(result["segments"]):
                start_td = timedelta(seconds=segment['start'])
                end_td = timedelta(seconds=segment['end'])
                final_srt_content += f"{i+1}\n{format_timedelta_srt(start_td)} --> {format_timedelta_srt(end_td)}\n{segment['text'].strip()}\n\n"

            print("âœ… æ–°å­—å¹•ç”¢ç”Ÿå®Œæˆï¼Œæº–å‚™ç·¨è¼¯")
            # Show the subtitle editor window (needs to run in the main GUI thread)
            self.root.after(0, self.show_subtitle_editor, final_srt_content)

        except Exception as e:
             self.root.after(0, messagebox.showerror, "Whisper éŒ¯èª¤", f"ç‚ºåˆä½µå¾Œå½±ç‰‡ç”¢ç”Ÿæ–°å­—å¹•å¤±æ•—: {e}")
             print(f"âŒ ç‚ºåˆä½µå¾Œå½±ç‰‡ç”¢ç”Ÿæ–°å­—å¹•å¤±æ•—: {e}")
             traceback.print_exc() # Print detailed error info


    def show_subtitle_editor(self, subtitles_text):
        """Opens the subtitle editor window."""
        # This method is called via root.after, so it runs in the main thread
        editor_window = SubtitleEditorWindow(self.root, subtitles_text, self.save_edited_subtitles)
        self.root.wait_window(editor_window) # Pause main thread execution until editor closes

    def save_edited_subtitles(self, edited_text):
        """Saves the edited subtitles and prompts for final merge."""
        self.final_srt_path = os.path.join(self.output_dir, "final_merged.srt") # Ensure path is set
        try:
            with open(self.final_srt_path, "w", encoding="utf-8") as f:
                f.write(edited_text)
            print(f"âœ… å­—å¹•å·²å„²å­˜è‡³ï¼š{self.final_srt_path}")
            # Now prompt the user for the final merge (needs to run in the main GUI thread)
            self.root.after(0, self.prompt_final_merge)
        except IOError as e:
             self.root.after(0, messagebox.showerror, "å„²å­˜éŒ¯èª¤", f"å„²å­˜ç·¨è¼¯å¾Œçš„å­—å¹•å¤±æ•—: {e}")
             print(f"âŒ å„²å­˜ç·¨è¼¯å¾Œçš„å­—å¹•å¤±æ•—: {e}")
             traceback.print_exc() # Print detailed error info

    def prompt_final_merge(self):
        """Asks the user for confirmation before embedding subtitles."""
        if messagebox.askyesno("ç¢ºèªåˆä½µ", "å­—å¹•ç·¨è¼¯å®Œæˆï¼Œæ˜¯å¦å°‡ç·¨è¼¯å¾Œçš„å­—å¹•åµŒå…¥åˆ°å½±ç‰‡ä¸­ï¼Ÿ\n\né€™å°‡éœ€è¦ä¸€æ®µæ™‚é–“ä¾†é‡æ–°ç·¨ç¢¼å½±ç‰‡ã€‚", icon='question'):
            # Start embedding in a separate thread
            threading.Thread(target=self.embed_subtitles_to_video).start()
        else:
            messagebox.showinfo("å–æ¶ˆ", "æœ€çµ‚åˆä½µå·²å–æ¶ˆã€‚è™•ç†å®Œæˆï¼Œä½†å­—å¹•æœªåµŒå…¥ã€‚")
            # Decide if we should quit or just go back to main window
            # For now, let the main window stay open


    def embed_subtitles_to_video(self):
        """Embeds the edited subtitles into the merged video."""
        final_output_with_subs = os.path.join(self.output_dir, "final_with_subs.mp4")
        print(f"ğŸš€ åµŒå…¥å­—å¹•ä¸­ ({self.final_srt_path})...")

        if not os.path.exists(self.merged_video_path):
             self.root.after(0, messagebox.showerror, "æª”æ¡ˆéŒ¯èª¤", f"åˆä½µå¾Œçš„å½±ç‰‡æœªæ‰¾åˆ°: {self.merged_video_path}")
             print(f"âŒ åˆä½µå¾Œçš„å½±ç‰‡æœªæ‰¾åˆ°: {self.merged_video_path}")
             return
        if not os.path.exists(self.final_srt_path):
             self.root.after(0, messagebox.showerror, "æª”æ¡ˆéŒ¯èª¤", f"ç·¨è¼¯å¾Œçš„å­—å¹•æª”æ¡ˆæœªæ‰¾åˆ°: {self.final_srt_path}")
             print(f"âŒ ç·¨è¼¯å¾Œçš„å­—å¹•æª”æ¡ˆæœªæ‰¾åˆ°: {self.final_srt_path}")
             return


        # FFmpeg command to embed subtitles (requires re-encoding video)
        # Using -c:v libx264 and -preset medium is a common choice.
        # Using forward slashes in the subtitles filter path is important for FFmpeg compatibility.
        video_codec_flags = ["-c:v", "libx264", "-preset", "medium", "-crf", "23"] # Hardcoded, could be in config
        audio_codec_flags = ["-c:a", "copy"]


        cmd_embed = [
            self.ffmpeg_path,
            "-i", self.merged_video_path,
            "-i", self.final_srt_path, # Input the new SRT file
            "-vf", f"subtitles='{self.final_srt_path.replace(os.sep, '/')}'", # subtitles filter with correct path syntax
            *video_codec_flags, # Video re-encoding flags
            *audio_codec_flags, # Audio copy flag
            final_output_with_subs,
            "-y" # Overwrite output file without asking
        ]
        print("FFmpeg command:", subprocess.list2cmdline(cmd_embed)) # Print command for debugging

        try:
            self.root.after(0, messagebox.showinfo, "é–‹å§‹åµŒå…¥", "å³å°‡é–‹å§‹åµŒå…¥å­—å¹•ï¼Œé€™å¯èƒ½éœ€è¦ä¸€äº›æ™‚é–“ã€‚è«‹ç¨å€™...")
            # Capture stdout and stderr for better error reporting
            # Adding creationflags=subprocess.CREATE_NO_WINDOW hides console window on Windows
            # Use capture_output=True/PIPE, text=True, and encoding="utf-8"
            # This is called from a background thread, Popen is OK.
            process = subprocess.Popen(cmd_embed, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, encoding="utf-8", creationflags=subprocess.CREATE_NO_WINDOW if os.name == 'nt' else 0)

            # Monitor progress (more advanced GUI needed for progress bar)
            # For now, just wait for it to finish
            stdout, stderr = process.communicate()

            if process.returncode != 0:
                 error_output = stderr # stderr is already text=True and decoded as utf-8
                 self.root.after(0, messagebox.showerror, "FFmpeg åµŒå…¥éŒ¯èª¤", f"åµŒå…¥å­—å¹•å¤±æ•— (è¿”å›ç¢¼: {process.returncode}).\nFFmpeg è¼¸å‡º:\n{error_output[:1000]}...") # Show first 1000 chars
                 print(f"âŒ åµŒå…¥å­—å¹•å¤±æ•— (è¿”å›ç¢¼: {process.returncode}).\nFFmpeg è¼¸å‡º:\n{error_output}")
                 traceback.print_exc() # Print detailed error info
            else:
                print(f"ğŸ‰ å®Œæˆï¼å¸¶å­—å¹•å½±ç‰‡è¼¸å‡ºï¼š{final_output_with_subs}")
                self.root.after(0, messagebox.showinfo, "å®Œæˆ", f"å½±ç‰‡è™•ç†å®Œæˆï¼å¸¶å­—å¹•å½±ç‰‡è¼¸å‡ºï¼š\n{final_output_with_subs}")


        except Exception as e:
             self.root.after(0, messagebox.showerror, "åµŒå…¥éŒ¯èª¤", f"åµŒå…¥å­—å¹•éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
             print(f"âŒ åµŒå…¥å­—å¹•éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
             traceback.print_exc() # Print detailed error info
        finally:
             # Decide whether to automatically quit or stay open
             # self.root.quit() # Option to quit after final step
             pass


    def cleanup_temp_clips(self):
        """Cleans up temporary clipped video files."""
        print("ğŸ§¹ æ¸…ç†è‡¨æ™‚æª”æ¡ˆä¸­...")
        # Ensure temp_clips list is populated correctly during clipping
        for clip in self.temp_clips:
             if os.path.exists(clip):
                 try:
                     os.remove(clip)
                 except OSError as e:
                     print(f"âš ï¸ ç„¡æ³•åˆªé™¤è‡¨æ™‚æª”æ¡ˆ {clip}: {e}")
        # Also remove the concat list file
        list_path = os.path.join(self.output_dir, "list.txt")
        if os.path.exists(list_path):
             try:
                 os.remove(list_path)
             except OSError as e:
                 print(f"âš ï¸ ç„¡æ³•åˆªé™¤è‡¨æ™‚æª”æ¡ˆ {list_path}: {e}")
        print("ğŸ§¹ æ¸…ç†è‡¨æ™‚æª”æ¡ˆå®Œæˆ")


# --- Entry Point ---
if __name__ == "__main__":
    root = tk.Tk()
    # Create the main application instance, which will set up the main window
    app = VideoEditorApp(root)
    # The main window is now visible and handles user interaction

    root.mainloop() # Start the Tkinter event loop